{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f43cd88-3539-41b2-a829-72321a5265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0ceaa-9776-4151-9f1a-4c3ad8ebbef6",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9758a2-d919-4f72-ac4d-80d00c59a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0d0a75-def2-48ce-8896-1895173e8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0db43f-73a6-43bd-9679-710cf8508a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c499d3-5146-4848-b7ba-edea90afe0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00564b6d-53c5-4b6a-8898-25749906a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_template = \"\"\"\n",
    "Tell me a {adjective} joke about {topic}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae54277-4fdb-406e-9a73-3e38f8ddbb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"topic\"],\n",
    "    template=my_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebf7622-1e1a-489b-b118-e32627c6d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"adjective\": \"funny\",\n",
    "    \"topic\": \"French\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187677a9-f99c-4e8a-8314-934d02322096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funny\n"
     ]
    }
   ],
   "source": [
    "print(user_input[\"adjective\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7583ed-1bb5-4d5a-b674-fc66522dfcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "    adjective=user_input[\"adjective\"], \n",
    "    topic=user_input[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e7098b-5637-4db7-9416-1e052b7855e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_16148\\1897946169.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(final_prompt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the French chef quit his job?\n",
      "\n",
      "Because he couldn't handle the pressure!\n"
     ]
    }
   ],
   "source": [
    "print(llm(final_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d70962-615b-44ce-a85e-535e1a49bb74",
   "metadata": {},
   "source": [
    "## Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c99304-c21d-4d97-b389-fd1469de76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13dc82dc-e0f3-4feb-9969-ae861f8ba2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d6e9a2-b473-4411-b53b-e2548b357283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = ChatOpenAI()\n",
    "chat = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb46fdff-960c-4468-8a58-1518d76086cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{user_input}\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "222dabb6-f736-481e-8161-477e31291318",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user_input = \"How many hours have one year?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3a1de0-556c-4a27-b615-732b05b4a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_16148\\1251095669.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chat(chat_template.format_messages(user_input=my_user_input))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One year typically has 8,760 hours. This is calculated by taking the number of days in a year (365) and multiplying it by the number of hours in a day (24):\\n\\n\\\\[ \\n365 \\\\text{ days/year} \\\\times 24 \\\\text{ hours/day} = 8,760 \\\\text{ hours/year} \\n\\\\]\\n\\nIn a leap year, which has 366 days, there are 8,784 hours:\\n\\n\\\\[ \\n366 \\\\text{ days/year} \\\\times 24 \\\\text{ hours/day} = 8,784 \\\\text{ hours/year} \\n\\\\]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 23, 'total_tokens': 148, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-9e3f5485-793c-4f8b-83c5-10e0e8e1d790-0', usage_metadata={'input_tokens': 23, 'output_tokens': 125, 'total_tokens': 148, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_template.format_messages(user_input=my_user_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
