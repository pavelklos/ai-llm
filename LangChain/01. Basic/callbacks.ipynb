{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9751170-8a93-45f3-b0a0-c9edc7b2eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e236c6c0-9ec8-4bb7-88b4-a41b240353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4b2ec-2155-4126-a18e-774c79cafeba",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448908ed-5d1a-4e0e-aa39-88e19fa4190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c79bb8-3cf4-4112-9b62-2455b92fb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_17612\\3827519468.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    }
   ],
   "source": [
    "# llm = ChatOpenAI()\n",
    "llm = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=\"Tell me a joke about {input}\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19981a0b-7b53-487e-ae19-2501dfa185bf",
   "metadata": {},
   "source": [
    "### Without callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f62b733-c636-49f1-a843-01739e93ee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'bear',\n",
       " 'text': 'Why do bears have hairy coats?\\n\\nBecause they look silly in jackets!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.run(input=\"bear\")\n",
    "chain.invoke(input=\"bear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f9903-6a19-4933-92b2-c237f26a2852",
   "metadata": {},
   "source": [
    "### With callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915dad73-860e-479b-83b9-87b53a2dc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = StdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16886ef-d2e2-4712-808c-c69a658c70ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'bear',\n",
       " 'text': 'Why do bears have hairy coats? \\n\\nBecause they look silly in sweaters!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.run(input=\"bear\", callbacks=[handler])\n",
    "chain.invoke(input=\"bear\", callbacks=[handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fde176-676a-4fe6-b59c-940ba28b021f",
   "metadata": {},
   "source": [
    "## Customized Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7de8f9-b52b-4b80-9996-350181033382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c8aa3b-07db-4316-a38b-2b8cd5cf686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_end(self, response, **kwargs) -> None:\n",
    "        print(f\"REPONSE: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba22baac-3296-4998-a096-65ea7d000d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'whale',\n",
       " 'text': 'Why did the whale cross the ocean?\\n\\nTo get to the other tide!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.run(input=\"whale\", callbacks=[MyCustomHandler()])\n",
    "chain.invoke(input=\"whale\", callbacks=[MyCustomHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf49ee-cdca-43b6-9b63-35d5d8cf16c9",
   "metadata": {},
   "source": [
    "## Callback to check OpenAI costs, token usage, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f67fbae-9285-4eb4-ab42-2d70f2d5275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30897e7a-beb0-48ad-865a-33d82635c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    # chain.run(input=\"elephant\")\n",
    "    chain.invoke(input=\"elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5de3850-42a5-4645-81b8-28c0b07afe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 28\n",
      "\tPrompt Tokens: 13\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 15\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $1.0949999999999998e-05\n"
     ]
    }
   ],
   "source": [
    "print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee1a32-03a8-4729-a2f6-19a85c85d7ef",
   "metadata": {},
   "source": [
    "## scientific_to_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebdb138-eb40-48a0-8055-be406d34f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scientific_to_decimal(sci_str):\n",
    "    # Remove any non-numeric characters except 'e', '-', '.'\n",
    "    clean_str = ''.join(c for c in sci_str if c.isdigit() or c in 'e-.')\n",
    "    \n",
    "    # Convert to float\n",
    "    num = float(clean_str)\n",
    "    \n",
    "    # Format to 5 decimal places\n",
    "    return f\"{num:.5f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5d8f2a-8179-450a-b78c-c14906167f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00005\n"
     ]
    }
   ],
   "source": [
    "result = scientific_to_decimal(\"$4.95e-05\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a97b00d-53c1-467c-bf25-72a8fcb159cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00001\n"
     ]
    }
   ],
   "source": [
    "result = scientific_to_decimal(\"$1.0949999999999998e-05\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
