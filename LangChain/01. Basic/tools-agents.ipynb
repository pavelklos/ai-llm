{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2586ef-a7d7-497d-ba15-adbf4f610715",
   "metadata": {},
   "source": [
    "## Agents (SerpApi, LLMMathChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bed6ea-37d4-4b75-83b0-2326a44c17c5",
   "metadata": {},
   "source": [
    "### original code [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b08c08d-3011-49a4-a584-d2cf5397b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import load_tools\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain.llms import OpenAI\n",
    "# tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "# agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad83bb-6e1c-4749-8908-5c846476c9b7",
   "metadata": {},
   "source": [
    "## Test Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01f6479-0d44-44b6-bdb2-e73c8f743997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results\n",
    "# !pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3c8201-d7b6-49b2-87c6-3c3bf1391f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "serpapi_api_key = os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "# from getpass import getpass\n",
    "\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key: \")\n",
    "# if \"SERPAPI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"SERPAPI_API_KEY\"] = getpass(\"Enter SerpAPI key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daebf8-53ee-4840-8766-b21061baac9b",
   "metadata": {},
   "source": [
    "### Tool 'calculator' (math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93aa4c30-76c2-4c62-8901-d6f9735fa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numexpr\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Expression should be a single line mathematical expression\n",
    "    that solves the problem.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Bind the calculator tool to the model\n",
    "llm_with_tools = llm.bind_tools(tools=[calculator], tool_choice=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa926ed-6a8c-453f-85fd-4c6c6dfa0309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_5xP8U9uLOvx8VJZ2xayanXeI', 'function': {'arguments': '{\"expression\":\"551368 / 82\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 105, 'total_tokens': 124, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-5e043fb4-db78-4c02-aba2-c49a4e553450-0' tool_calls=[{'name': 'calculator', 'args': {'expression': '551368 / 82'}, 'id': 'call_5xP8U9uLOvx8VJZ2xayanXeI', 'type': 'tool_call'}] usage_metadata={'input_tokens': 105, 'output_tokens': 19, 'total_tokens': 124, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What is 551368 divided by 82?\"\n",
    "result = llm_with_tools.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a8b4b-842d-4fc4-954b-82d71000e002",
   "metadata": {},
   "source": [
    "### Tool 'web_search' (SerpAPIWrapper) + 'calculator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2167a556-26e5-4f53-94c4-a2a82c2663a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "# Create SerpAPI search tool\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Perform a web search using SerpAPI and return search results.\"\"\"\n",
    "    search = SerpAPIWrapper()\n",
    "    return search.run(query)\n",
    "\n",
    "# Create a calculator tool for mathematical operations\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Perform mathematical calculations.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Initialize the OpenAI model with both tools\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(\n",
    "    tools=[web_search, calculator], \n",
    "    tool_choice=\"any\"\n",
    ")\n",
    "\n",
    "# Function to demonstrate tool usage\n",
    "def demonstrate_tool_calling():\n",
    "    # Example 1: Web Search\n",
    "    web_search_query = \"What is the latest breakthrough in AI?\"\n",
    "    web_search_response = llm_with_tools.invoke(\n",
    "        f\"Please search the web and summarize: {web_search_query}\"\n",
    "    )\n",
    "    print(\"Web Search Response:\")\n",
    "    print(web_search_response)\n",
    "    \n",
    "    # Check for tool calls\n",
    "    if web_search_response.tool_calls:\n",
    "        for tool_call in web_search_response.tool_calls:\n",
    "            print(\"\\nTool Call Details:\")\n",
    "            print(f\"Tool Name: {tool_call['name']}\")\n",
    "            print(f\"Arguments: {tool_call['args']}\")\n",
    "    \n",
    "    # Example 2: Calculator\n",
    "    math_query = \"What is 256 multiplied by 13, then divided by 4?\"\n",
    "    math_response = llm_with_tools.invoke(\n",
    "        f\"Please calculate: {math_query}\"\n",
    "    )\n",
    "    print(\"\\nMath Calculation Response:\")\n",
    "    print(math_response)\n",
    "    \n",
    "    # Check for tool calls\n",
    "    if math_response.tool_calls:\n",
    "        for tool_call in math_response.tool_calls:\n",
    "            print(\"\\nTool Call Details:\")\n",
    "            print(f\"Tool Name: {tool_call['name']}\")\n",
    "            print(f\"Arguments: {tool_call['args']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b782212-6ed1-4f5f-ba5d-54ff089cb23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Search Response:\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_LrhjtlJ9vPpovmyqxYJTrE66', 'function': {'arguments': '{\"query\":\"latest breakthrough in AI 2023\"}', 'name': 'web_search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 82, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-f15cdda8-e5c6-4e65-a1a3-74960adc5790-0' tool_calls=[{'name': 'web_search', 'args': {'query': 'latest breakthrough in AI 2023'}, 'id': 'call_LrhjtlJ9vPpovmyqxYJTrE66', 'type': 'tool_call'}] usage_metadata={'input_tokens': 82, 'output_tokens': 21, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Tool Call Details:\n",
      "Tool Name: web_search\n",
      "Arguments: {'query': 'latest breakthrough in AI 2023'}\n",
      "\n",
      "Math Calculation Response:\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_IwvpO36m2j0x2dLPDDYDaWX4', 'function': {'arguments': '{\"expression\":\"(256 * 13) / 4\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 85, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-be9ec64a-1886-4c25-bac0-46059f0e91f1-0' tool_calls=[{'name': 'calculator', 'args': {'expression': '(256 * 13) / 4'}, 'id': 'call_IwvpO36m2j0x2dLPDDYDaWX4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 85, 'output_tokens': 23, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Tool Call Details:\n",
      "Tool Name: calculator\n",
      "Arguments: {'expression': '(256 * 13) / 4'}\n"
     ]
    }
   ],
   "source": [
    "# Run the demonstration\n",
    "demonstrate_tool_calling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a33855b-2133-4be2-a468-1e63e2846af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced: Chaining tool calls\n",
    "def advanced_tool_chain():\n",
    "    complex_query = \"Find the current population of Japan and then multiply it by 2\"\n",
    "    \n",
    "    # First, search for population\n",
    "    population_search = llm_with_tools.invoke(\n",
    "        \"What is the current population of Japan?\"\n",
    "    )\n",
    "    \n",
    "    # Extract population from search results\n",
    "    if population_search.tool_calls:\n",
    "        search_result = web_search.invoke(\n",
    "            population_search.tool_calls[0]['args']['query']\n",
    "        )\n",
    "        \n",
    "        # Use calculator to perform multiplication\n",
    "        calculation_response = llm_with_tools.invoke(\n",
    "            f\"Multiply the population {search_result} by 2\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\nAdvanced Tool Chain Result:\")\n",
    "        print(calculation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df31e926-1ae7-4614-bba5-06828e5e5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Tool Chain Result:\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_t05vl1BaGHsdCF07hSNpP9Nl', 'function': {'arguments': '{\"expression\":\"124.5 * 2\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 96, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d902ce00-565a-4c2f-a569-39d37787878e-0' tool_calls=[{'name': 'calculator', 'args': {'expression': '124.5 * 2'}, 'id': 'call_t05vl1BaGHsdCF07hSNpP9Nl', 'type': 'tool_call'}] usage_metadata={'input_tokens': 96, 'output_tokens': 20, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run advanced example\n",
    "advanced_tool_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f4f30-9396-4ad1-af3d-25f1104855b1",
   "metadata": {},
   "source": [
    "## TODO: Agents (SerpApi, LLMMathChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5509d6-7ac4-455f-aa0a-f0895efc45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import load_tools\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain.llms import OpenAI\n",
    "# tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "# agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
