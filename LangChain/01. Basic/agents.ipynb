{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca5bbbf-142b-48ed-89f2-18c63eac1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1959bf0d-9b66-473f-953a-0e2a600a7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0647a-3384-4a8d-bc5a-446b58a9ec80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic App: Question & Answering from Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196e2414-39ff-4643-9c31-b130697e3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b191eb7d-a9df-47a6-95ac-fdec0b0b1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OpenAI()\n",
    "llm = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ecd8a-34b9-4489-9b6d-7b257919737a",
   "metadata": {},
   "source": [
    "### Load text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9801a4d-ecd7-460a-a4db-f0a1711163f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e01cbe49-38ce-40d2-8e01-01052483fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = TextLoader(\"data/be-good.txt\")\n",
    "loader = TextLoader(\"../../data/be-good.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afff80c1-1cd1-408e-ac28-2a8594af2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ff8b1-c63c-48b4-acaf-b959b98e770d",
   "metadata": {},
   "source": [
    "### Document is loaded as Python list with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684f2ccb-9ec4-4384-b875-3f89608292f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f712992-beac-420c-b94e-1db729bd9508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb6e6d1-765b-4762-8213-0c56e4829427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../../data/be-good.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(document[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef34dd2-aace-45c9-a87b-c3967370f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document.\n"
     ]
    }
   ],
   "source": [
    "print(f\"You have {len(document)} document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb653b8-8035-40bf-b73c-542c90499486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your document has 16710 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your document has {len(document[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8fbef1-4447-4ef5-ba21-9211b4486904",
   "metadata": {},
   "source": [
    "### Split document in small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18899367-8f8e-4d47-a61c-8041bafb4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f31176-187b-4e0c-819a-dd35b7e61ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0147e8c9-70fb-4990-8bf6-c77ea283200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86820a0a-e307-4bb9-9b69-24284d9f0754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 8 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now you have {len(document_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756c471-5af1-4ba4-8f90-cfc70e897155",
   "metadata": {},
   "source": [
    "### Convert text chunks in numeric vectors (called \"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e40b2df-53ad-4984-8972-cf7258b762fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e7c4f6-2116-4ce1-8349-640fa6591970",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67881eb4-7418-4423-b4b9-b750e4a579cf",
   "metadata": {},
   "source": [
    "### Load embeddings to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75acf1fc-25a4-437c-bd1b-7310a83bae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a2e4dbc-af28-497f-877a-933347c747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_embeddings = FAISS.from_documents(document_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ae930c-5d99-45c5-8597-52457d22b6d1",
   "metadata": {},
   "source": [
    "### Create Retrieval Question & Answering Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e30338bd-58ae-467d-a01e-8bef3ae435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9bed1ac-d148-4fb1-9382-bc58db111d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=stored_embeddings.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a96c6d-a473-4ecc-885d-55f1618487d4",
   "metadata": {},
   "source": [
    "### Now we have Question & Answering App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c432c922-984b-49b9-b3c1-4a6c5d2ccd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "What is this article about? \n",
    "Describe it in less than 100 words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d407274-69c0-4d7f-8def-5e2275027a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '\\nWhat is this article about? \\nDescribe it in less than 100 words.\\n',\n",
       " 'result': \"The article discusses the importance of creating products that genuinely meet users' needs, emphasizing that startups should focus on making something people want rather than obsessing over their business model initially. It suggests that benevolent intentions in business can lead to success, using examples like Craigslist and Google. The author argues that being good and prioritizing users can serve as a compass for decision-making in startups, ultimately fostering a positive environment that attracts talent and investment. The piece reflects on the intersection of altruism and entrepreneurship.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QA_chain.run(question)\n",
    "QA_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87459203-207e-4180-af54-1a48457143b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"\"\"\n",
    "And how does it explain how to create somethin people want?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86947fdc-3d59-465c-b1a9-a061421bccb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '\\nWhat is this article about? \\nDescribe it in less than 100 words.\\n',\n",
       " 'result': 'The article discusses the importance of creating products that people want while not overly focusing on immediate profitability. It suggests that startups can operate with benevolent aims, similar to charities, and still achieve success. Examples like Craigslist and Google illustrate how companies can prioritize user needs and genuine growth over profits. The author emphasizes that being good and benevolent can attract talent and support, acting as a guiding principle for decision-making in startups. Overall, it advocates for a user-centric approach in entrepreneurship.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QA_chain.run(question2)\n",
    "QA_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643a907-1d84-4583-8c1d-f3062a7172eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c852a0af-e258-47c3-b40d-5298aed59ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33694fdb-092c-49f4-a823-30dcae683e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020442F07850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020442E9B750>, root_client=<openai.OpenAI object at 0x00000204430C7550>, root_async_client=<openai.AsyncOpenAI object at 0x0000020442FBF210>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020442F07850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020442E9B750>, root_client=<openai.OpenAI object at 0x00000204430C7550>, root_async_client=<openai.AsyncOpenAI object at 0x0000020442FBF210>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# llm=OpenAI()\n",
    "llm=ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "tool_names = [\"llm-math\"]\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb773d04-eb42-44be-a790-096512b7618f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_20560\\3660245525.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(tools,\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True,\n",
    "                         max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68206e03-0099-4f39-8b7b-30f18bcb63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the product of 133 and 142, I need to multiply these two numbers together.  \n",
      "Action: Calculator  \n",
      "Action Input: 133 * 142  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 18886\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: 18886\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 133 by 142?', 'output': '18886'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.run(\"What is 133 by 142?\")\n",
    "agent.invoke(\"What is 133 by 142?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06baea-c16e-4566-8f6d-ea9f473454d9",
   "metadata": {},
   "source": [
    "### Let's make agent fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1f6740e-3c43-4e9f-b454-dc8ae5af7612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question, I need to recall historical information about Napoleon Bonaparte's marriages. I know he was married twice. His first wife was Joséphine de Beauharnais, and his second wife was Marie Louise of Austria. Since the question asks for \"the wife\" without specifying, it is likely referring to his first and more well-known spouse. \n",
      "\n",
      "Action: None needed for calculations; I will provide the answer based on historical knowledge.\n",
      "\n",
      "Final Answer: Joséphine de Beauharnais was the wife of Napoleon Bonaparte.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the wife of Napoleon Bonaparte?',\n",
       " 'output': 'Joséphine de Beauharnais was the wife of Napoleon Bonaparte.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.run(\"Who was the wife of Napoleon Bonaparte?\")\n",
    "agent.invoke(\"Who was the wife of Napoleon Bonaparte?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aaefd6-fbf6-4fcc-a4e7-ff7327dac84b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Custom Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfdf7465-83ca-4106-a1dd-26f5d7fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional\n",
    "# from langchain.tools import BaseTool\n",
    "# from langchain.callbacks.manager import AsyncCallbackManagerForToolRun\n",
    "# from langchain.callbacks.manager import CallbackManagerForToolRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a96d646-097f-4515-aea1-40b4e97a4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomSearchTool(BaseTool):\n",
    "#     name = \"article search\"\n",
    "#     description = \"useful for when you need to answer questions about our article\"\n",
    "\n",
    "#     def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "#         store = stored_embeddings.as_retriever()\n",
    "#         docs = store.get_relevant_documents(query)\n",
    "#         text_list = [doc.page_content for doc in docs]\n",
    "#         return \"\\n\".join(text_list)\n",
    "\n",
    "#     async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "#         \"\"\"Use the tool asynchronously.\"\"\"\n",
    "#         raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4bfa1d2-5ba9-403a-a51b-c0a122499b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from typing import Optional, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f98cbcc-1bf1-4a24-96af-8844a577ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSearchTool(BaseTool):\n",
    "    name: str = \"article search\"  # Add type annotation here\n",
    "    description: str = \"useful for when you need to answer questions about our article\"  # Add type annotation here\n",
    "    \n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        store = stored_embeddings.as_retriever()\n",
    "        docs = store.get_relevant_documents(query)\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b5533be-1ca3-4bb9-bad7-8c7d3618525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [CustomSearchTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True, \n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcf94ee6-d553-4902-b366-b6a70b0da79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the content of the article to summarize it.  \n",
      "Action: article search  \n",
      "Action Input: \"What is this article about?\"  \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_20560\\1292071831.py:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = store.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mBe good\n",
      "April 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we started Y Combinator we came up with the\n",
      "phrase that became our motto: Make something people want.  We've\n",
      "learned a lot since then, but if I were choosing now that's still\n",
      "the one I'd pick.Another thing we tell founders is not to worry too much about the\n",
      "business model, at least at first.  Not because making money is\n",
      "unimportant, but because it's so much easier than building something\n",
      "great.A couple weeks ago I realized that if you put those two ideas\n",
      "together, you get something surprising.  Make something people want.\n",
      "Don't worry too much about making money.  What you've got is a\n",
      "description of a charity.When you get an unexpected result like this, it could either be a\n",
      "bug or a new discovery.  Either businesses aren't supposed to be\n",
      "like charities, and we've proven by reductio ad absurdum that one\n",
      "or both of the principles we began with is false.  Or we have a new\n",
      "idea.I suspect it's the latter, because as soon as this thought occurred\n",
      "to me, a whole bunch of other things fell into place.ExamplesFor example, Craigslist.  It's not a charity, but they run it like\n",
      "one.  And they're astoundingly successful.  When you scan down the\n",
      "list of most popular web sites, the number of employees at Craigslist\n",
      "looks like a misprint. Their revenues aren't as high as they could\n",
      "be, but most startups would be happy to trade places with them.In Patrick O'Brian's novels, his captains always try to get upwind\n",
      "of their opponents.  If you're upwind, you decide when and if to\n",
      "engage the other ship.  Craigslist is effectively upwind of enormous\n",
      "revenues.  They'd face some challenges if they wanted to make more,\n",
      "but not the sort you face when you're tacking upwind, trying to\n",
      "force a crappy product on ambivalent users by spending ten times\n",
      "as much on sales as on development.  [1]I'm not saying startups should aim to end up like Craigslist.\n",
      "They're a product of unusual circumstances.  But they're a good\n",
      "model for the early phases.Google looked a lot like a charity in the beginning. They didn't\n",
      "have ads for over a year.  At year 1, Google was indistinguishable\n",
      "from a nonprofit.  If a nonprofit or government organization had\n",
      "started a project to index the web, Google at year 1 is the limit\n",
      "of what they'd have produced.Back when I was working on spam filters I thought it would be a\n",
      "good idea to have a web-based email service with good spam filtering.\n",
      "I wasn't thinking of it as a company.  I just wanted to keep people\n",
      "from getting spammed.  But as I thought more about this project, I\n",
      "realized it would probably have to be a company.  It would cost\n",
      "something to run, and it would be a pain to fund with grants and\n",
      "donations.That was a surprising realization.  Companies often claim to be\n",
      "benevolent, but it was surprising to realize there were purely\n",
      "benevolent projects that had to be embodied as companies to work.I didn't want to start another company, so I didn't do it.  But if\n",
      "it and they've been growing rapidly.  And yet for most of Octopart's\n",
      "life, the biggest distributor, Digi-Key, has been trying to force\n",
      "them take their prices off the site.  Octopart is sending them\n",
      "customers for free, and yet Digi-Key is trying to make that traffic\n",
      "stop.  Why?  Because their current business model depends on\n",
      "overcharging people who have incomplete information about prices.\n",
      "They don't want search to work.The Octoparts are the nicest guys in the world.  They dropped out\n",
      "of the PhD program in physics at Berkeley to do this.  They just\n",
      "wanted to fix a problem they encountered in their research.  Imagine\n",
      "how much time you could save the world's engineers if they could\n",
      "do searches online.  So when I hear that a big, evil company is\n",
      "trying to stop them in order to keep search broken, it makes me\n",
      "really want to help them. It makes me spend more time on the Octoparts\n",
      "than I do with most of the other startups we've funded.  It just\n",
      "made me spend several minutes telling you how great they are.  Why?\n",
      "Because they're good guys and they're trying to help the world.If you're benevolent, people will rally around you: investors,\n",
      "customers, other companies, and potential employees.  In the long\n",
      "term the most important may be the potential employees.  I think\n",
      "everyone knows now that \n",
      "good hackers are much better than mediocre\n",
      "ones.  If you can attract the best hackers to work for you, as\n",
      "Google has, you have a big advantage.  And the very best hackers\n",
      "tend to be idealistic.  They're not desperate for a job.  They can\n",
      "work wherever they want.  So most want to work on things that will\n",
      "make the world better.CompassBut the most important advantage of being good is that it acts as\n",
      "a compass.  One of the hardest parts of doing a startup is that you\n",
      "have so many choices.  There are just two or three of you, and a\n",
      "thousand things you could do. How do you decide?Here's the answer: Do whatever's best for your users.  You can hold\n",
      "onto this like a rope in a hurricane, and it will save you if\n",
      "anything can.  Follow it and it will take you through everything\n",
      "you need to do.It's even the answer to questions that seem unrelated, like how to\n",
      "convince investors to give you money.  If you're a good salesman,\n",
      "you could try to just talk them into it.  But the more reliable\n",
      "route is to convince them through your users: if you make something\n",
      "users love enough to tell their friends, you grow exponentially,\n",
      "and that will convince any investor.Being good is a particularly useful strategy for making decisions\n",
      "in complex situations because it's stateless.  It's like telling\n",
      "the truth.  The trouble with lying is that you have to remember\n",
      "everything you've said in the past to make sure you don't contradict\n",
      "yourself.  If you tell the truth you don't have to remember anything,\n",
      "and that's a really useful property in domains where things happen\n",
      "fast.For example, Y Combinator has now invested in 80 startups, 57 of\n",
      "which are still alive.  (The rest have died or merged or been\n",
      "usually do a very good job.It's one of the standard career paths of trustafarians to start\n",
      "some vaguely benevolent business.  The problem with most of them\n",
      "is that they either have a bogus political agenda or are feebly\n",
      "executed.  The trustafarians' ancestors didn't get rich by preserving\n",
      "their traditional culture; maybe people in Bolivia don't want to\n",
      "either.  And starting an organic farm, though it's at least\n",
      "straightforwardly benevolent, doesn't help people on the scale that\n",
      "Google does.Most explicitly benevolent projects don't hold themselves sufficiently\n",
      "accountable.  They act as if having good intentions were enough to\n",
      "guarantee good effects.[3] Users dislike their\n",
      "new operating system so much that they're starting petitions to\n",
      "save the old one.  And the old one was nothing special.  The hackers\n",
      "within Microsoft must know in their hearts that if the company\n",
      "really cared about users they'd just advise them to switch to OSX.Thanks to Trevor Blackwell, Paul Buchheit, Jessica Livingston,\n",
      "and Robert Morris for reading drafts of this.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: The article discusses the philosophy behind startup success, emphasizing the importance of creating something people want without initially worrying about profitability. It suggests that benevolent intentions can lead to success and attract talent, using examples like Craigslist and Google to illustrate how businesses can operate with a charitable mindset while still thriving. The author argues that focusing on user needs can guide decision-making and help navigate the complexities of running a startup.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this article about? Describe it in less than 100 words.',\n",
       " 'output': 'The article discusses the philosophy behind startup success, emphasizing the importance of creating something people want without initially worrying about profitability. It suggests that benevolent intentions can lead to success and attract talent, using examples like Craigslist and Google to illustrate how businesses can operate with a charitable mindset while still thriving. The author argues that focusing on user needs can guide decision-making and help navigate the complexities of running a startup.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.run(\"What is this article about? Describe it in less than 100 words.\")\n",
    "agent.invoke(\"What is this article about? Describe it in less than 100 words.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
