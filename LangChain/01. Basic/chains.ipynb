{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551abdb6-ca7d-4625-8526-8c1cd5b04219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43746676-aece-49a8-9205-be1e2844d873",
   "metadata": {},
   "source": [
    "## Simple chain with LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826a3c4c-7922-4d89-ad4c-d13c6cc84a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f639bf9-fd55-46d2-8691-6b828d78e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0087663-b9b1-45af-9497-c914ea6de46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = ChatOpenAI()\n",
    "chat = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3296aeb5-0720-4a11-a8c6-bb2d800859a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c38b38-a3fb-478f-a3ce-eec1de45f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_23904\\2642925554.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655659b9-b3ec-47aa-9889-594caed654ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"AI Applications and AI Courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb90db2-1d9e-48dc-ba01-1d1ff426d823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'AI Applications and AI Courses',\n",
       " 'text': \"Choosing a name for a company that focuses on AI applications and courses should convey innovation, technology, and education. Here are some suggestions:\\n\\n1. **AICraft Academy**\\n2. **IntelliLearn AI**\\n3. **AI Nexus Solutions**\\n4. **SmartCourse AI**\\n5. **Cognitive Code Labs**\\n6. **AI Innovate**\\n7. **LearnAI Technologies**\\n8. **Aptitude AI**\\n9. **NextGen AI Institute**\\n10. **AI Synergy Hub**\\n\\nMake sure the name you choose resonates with your target audience and reflects the mission and vision of your company. Additionally, check for domain availability if you're considering an online presence!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm_chain.run(product)\n",
    "llm_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52c0a5-a378-4e16-b40f-c83ab9a79d05",
   "metadata": {},
   "source": [
    "## Simple chain with LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429da947-87a3-4a53-9ad5-d71c80227f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d36070-bd77-444c-8e73-365011de6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"What is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74196a65-abfa-4d7a-9cd0-f821be7475e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_llm_chain = prompt_template | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd18e3ef-7fef-4ccc-8af1-af1b4eb52744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some name ideas for a company that specializes in AI applications and courses:\\n\\n1. **AI Nexus**\\n2. **SmartLearn AI**\\n3. **Cognitive Solutions**\\n4. **AI Innovate**\\n5. **FutureMind Academy**\\n6. **IntelliCraft**\\n7. **AI Mastery Hub**\\n8. **Neural Network Labs**\\n9. **Aptitude AI**\\n10. **Insight AI Solutions**\\n11. **AI Empower**\\n12. **TechThrive AI**\\n13. **LearnAI Studio**\\n14. **AI SkillForge**\\n15. **Visionary AI Institute**\\n\\nFeel free to mix and match or modify these suggestions to find the perfect fit for your company!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_llm_chain.invoke(\n",
    "    {\"product\": product}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ac6ff-45c7-4247-a302-e4abf1671218",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "846f107e-774b-4a3a-8838-8e2cd9db4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e4a119-73e3-4347-a60d-cacd445514a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: translate to Spanish\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following text to spanish:\"\n",
    "    \"\\n\\n{Text}\"\n",
    ")\n",
    "\n",
    "# chain 1: input= Text and output= Spanish_Translation\n",
    "chain_one = LLMChain(\n",
    "    llm=chat, \n",
    "    prompt=first_prompt, \n",
    "    output_key=\"Spanish_Translation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c093d793-2764-456e-b224-41557856ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2: summarize\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following text in 1 sentence:\"\n",
    "    \"\\n\\n{Text}\"\n",
    ")\n",
    "\n",
    "# chain 2: input= Text and output= summary\n",
    "chain_two = LLMChain(\n",
    "    llm=chat, \n",
    "    prompt=second_prompt, \n",
    "    output_key=\"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabc82ab-1d5f-4fdf-a950-9045a5ddeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: identify language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following text:\\n\\n{Spanish_Translation}\"\n",
    ")\n",
    "\n",
    "# chain 3: input= Spanish_Translation and output= language\n",
    "chain_three = LLMChain(\n",
    "    llm=chat, \n",
    "    prompt=third_prompt,\n",
    "    output_key=\"language\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "519fa7d9-f817-41d7-b9a1-d5f2821c169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(\n",
    "    llm=chat, \n",
    "    prompt=fourth_prompt,\n",
    "    output_key=\"followup_message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60b59ca0-45a0-481c-b792-296b5bd20be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Text \n",
    "# and output= Spanish_Translation,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Text\"],\n",
    "    output_variables=[\"Spanish_Translation\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf9a5182-9c01-466e-80ba-353b9c8ac1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "Being in a start-up myself, I read this book to find comfort \n",
    "and confirmation about the volatility and emotional roller-coaster \n",
    "that comes with a working at the brink of software-as-a service. \n",
    "This book was just what it promised - interviews from some of the \n",
    "great successes in SV and elsewhere, their humble and sometimes \n",
    "difficult beginnings ('against all odds') that I am experiencing \n",
    "right now. It's not a literary piece of work - never intended to \n",
    "be, on the contrary, I felt the writing style was just what fits \n",
    "with a life in the fast lane - little time, easy to read chapters, \n",
    "inspiring and thank god, very 'down to earth.'\n",
    "\n",
    "The one critical point I would like to make: I am somewhat \n",
    "perplexed how the companies were chosen - there are so many \n",
    "other companies that could have fit the profile which seem \n",
    "much more of a success than some of the companies/products in \n",
    "the book (gmail? Comm'on, I guess the author wanted to have \n",
    "Google in there, but didn't get an interview so she went with \n",
    "gmail?). Other great companies are easy to find - they don't\n",
    "even need to be in the consumer space. How about Salesforce.com? \n",
    "I definitely liked the mix of 'new' and 'experienced' start ups. \n",
    "\n",
    "This book was a breeze to read and insightful for us start-up \n",
    "enterpreneurs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bf2129d-5bc4-436c-b30d-ada61448e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': \"\\nBeing in a start-up myself, I read this book to find comfort \\nand confirmation about the volatility and emotional roller-coaster \\nthat comes with a working at the brink of software-as-a service. \\nThis book was just what it promised - interviews from some of the \\ngreat successes in SV and elsewhere, their humble and sometimes \\ndifficult beginnings ('against all odds') that I am experiencing \\nright now. It's not a literary piece of work - never intended to \\nbe, on the contrary, I felt the writing style was just what fits \\nwith a life in the fast lane - little time, easy to read chapters, \\ninspiring and thank god, very 'down to earth.'\\n\\nThe one critical point I would like to make: I am somewhat \\nperplexed how the companies were chosen - there are so many \\nother companies that could have fit the profile which seem \\nmuch more of a success than some of the companies/products in \\nthe book (gmail? Comm'on, I guess the author wanted to have \\nGoogle in there, but didn't get an interview so she went with \\ngmail?). Other great companies are easy to find - they don't\\neven need to be in the consumer space. How about Salesforce.com? \\nI definitely liked the mix of 'new' and 'experienced' start ups. \\n\\nThis book was a breeze to read and insightful for us start-up \\nenterpreneurs.\\n\",\n",
       " 'Spanish_Translation': \"Siendo parte de una start-up, leí este libro para encontrar consuelo y confirmación sobre la volatilidad y la montaña rusa emocional que conlleva trabajar al borde del software como servicio. Este libro fue justo lo que prometía: entrevistas con algunos de los grandes éxitos en Silicon Valley y en otros lugares, sus humildes y a veces difíciles comienzos ('contra todo pronóstico') que estoy experimentando en este momento. No es una obra literaria; nunca tuvo la intención de serlo. Al contrario, sentí que el estilo de escritura se ajustaba perfectamente a una vida en la vía rápida: poco tiempo, capítulos fáciles de leer, inspiradores y, gracias a Dios, muy 'realistas'.\\n\\nEl único punto crítico que me gustaría hacer: estoy algo perplejo por cómo se eligieron las empresas; hay tantas otras empresas que podrían haber encajado en el perfil y que parecen mucho más exitosas que algunas de las empresas/productos en el libro (¿Gmail? Vamos, supongo que la autora quería incluir a Google, pero no consiguió una entrevista, así que optó por Gmail). Otras grandes empresas son fáciles de encontrar; ni siquiera necesitan estar en el espacio del consumidor. ¿Qué tal Salesforce.com? Definitivamente me gustó la mezcla de start-ups 'nuevas' y 'experimentadas'.\\n\\nEste libro fue un soplo de aire fresco para leer y muy revelador para nosotros, los emprendedores de start-ups.\",\n",
       " 'summary': 'The book offers comforting and relatable insights through interviews with successful entrepreneurs, reflecting on the challenges of start-up life, though the selection of companies discussed raises some questions about representation.',\n",
       " 'followup_message': 'Respuesta: Estoy de acuerdo con la idea de que las entrevistas con emprendedores exitosos pueden ser muy reconfortantes y motivadoras, ya que ofrecen una visión realista de los desafíos que enfrentan en sus trayectorias. Sin embargo, es importante considerar la diversidad de las voces representadas en el libro. La experiencia de un emprendedor no siempre se traduce en la de otro, y sería enriquecedor escuchar también las historias de aquellos que provienen de contextos menos privilegiados o que han enfrentado barreras adicionales. Esto no solo ampliaría la comprensión de los retos en el mundo del emprendimiento, sino que también podría inspirar a una audiencia más amplia que busca iniciar sus propios proyectos.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall_chain(review)\n",
    "overall_chain.invoke(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3ad86-3204-482f-af67-319b3762e563",
   "metadata": {},
   "source": [
    "## Sequential Chain with LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf95299-4904-49b3-a257-3799633756d4",
   "metadata": {},
   "source": [
    "*Option 1: with the simpler syntax we get just the output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae7040ba-d692-4bf7-92ee-f5bc3e55f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b662d70-c350-4853-8c8c-bc50eae5d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequence_chain = {\"Spanish_Translation\": first_prompt | chat | StrOutputParser()} | third_prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ebec43-fe94-4bae-b92f-51b1c37ec76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The language of the text is Spanish.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequence_chain.invoke({\"Text\": review})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9210b61-fdae-4f51-b133-6791e5d4938c",
   "metadata": {},
   "source": [
    "*Option 2: with RunnablePassthrough we get input and output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8207651-7cf0-41de-8f43-100f095e0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6205f945-8c0f-4038-9c09-36af0a721413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: Text, output: Spanish_Translation\n",
    "first_chain = first_prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0159cc78-7560-4365-a0ca-a92d2bc497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: Text, output: summary\n",
    "second_chain = second_prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e888eee-1d0f-4e7b-baa3-6cb14017fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: Spanish_Translation, output: language\n",
    "third_chain = third_prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2e864a-1c3d-4917-8421-939dce2d33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: summary, output: followup_message\n",
    "fourth_chain = fourth_prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ee54257-86dc-4741-b9d5-6f21a1024616",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_plus_three_sequence_chain = {\"Spanish_Translation\": first_chain} | RunnablePassthrough.assign(language=third_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1fff75-f3d3-4f60-a1b1-9aa24977d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spanish_Translation': \"Siendo parte de una start-up, leí este libro para encontrar consuelo y confirmación sobre la volatilidad y la montaña rusa emocional que conlleva trabajar al borde del software como servicio. Este libro fue justo lo que prometía: entrevistas con algunos de los grandes éxitos en Silicon Valley y en otros lugares, sus humildes y a veces difíciles comienzos ('contra todo pronóstico') que estoy experimentando en este momento. No es una obra literaria - nunca tuvo la intención de serlo, al contrario, sentí que el estilo de escritura encajaba perfectamente con una vida en el carril rápido - poco tiempo, capítulos fáciles de leer, inspiradores y, gracias a Dios, muy 'realistas'.\\n\\nEl único punto crítico que me gustaría señalar: estoy algo perplejo sobre cómo se eligieron las empresas - hay muchas otras que podrían haber encajado en el perfil y que parecen ser mucho más exitosas que algunas de las empresas/productos en el libro (¿Gmail? Vamos, supongo que la autora quería incluir a Google, pero no consiguió una entrevista, así que se fue con Gmail?). Otras grandes empresas son fáciles de encontrar - ni siquiera necesitan estar en el espacio de consumo. ¿Qué tal Salesforce.com? Definitivamente me gustó la mezcla de start-ups 'nuevas' y 'experimentadas'.\\n\\nEste libro fue un soplo de aire fresco para leer y resultó muy útil para nosotros, los emprendedores de start-ups.\",\n",
       " 'language': 'The language of the text is Spanish.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_plus_three_sequence_chain.invoke({\"Text\": review})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b3598-1265-45e0-9957-dec4eb8b7146",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930fa5b8-dede-49a3-b6f3-010d638e1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_template = \"\"\"You are a very smart rock and roll professor. \\\n",
    "You are great at answering questions about rock and roll in a concise\\\n",
    "and easy to understand manner.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "politics_template = \"\"\"You are a very good politics professor. \\\n",
    "You are great at answering politics questions..\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "history_template = \"\"\"You are a very good history teacher. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "sports_template = \"\"\" You are a sports teacher.\\\n",
    "You are great at answering sports questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c30b8fc9-dfa5-45b5-8e30-2afb1ca65c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"rock\", \n",
    "        \"description\": \"Good for answering questions about rock and roll\", \n",
    "        \"prompt_template\": rock_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"politics\", \n",
    "        \"description\": \"Good for answering questions about politics\", \n",
    "        \"prompt_template\": politics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sports\", \n",
    "        \"description\": \"Good for answering questions about sports\", \n",
    "        \"prompt_template\": sports_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1f918fd-7491-499f-910b-879b3b86477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33ae3c67-712e-4c05-829d-907de1117be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=chat, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f61bdf8b-4d9c-4be4-880b-725f78fe245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=chat, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cde9cfbb-24c1-4076-b559-ed6f9839e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1626865b-1236-46cd-a2ce-0e5739a9f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm=chat, \n",
    "    prompt=router_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16eb58bb-fee2-47a0-ae88-24ccff7d22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_23904\\3038952769.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "725fc3c3-b7a7-42fb-86fa-00f0ad7c8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_23904\\3901969373.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"Who was Joe DiMaggio? Respond in less than 100 words\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Who was Joe DiMaggio? Respond in less than 100 words.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Joe DiMaggio was an American professional baseball player, widely regarded as one of the greatest center fielders in the history of Major League Baseball (MLB). He played 13 seasons for the New York Yankees from 1936 to 1951 and was known for his exceptional hitting, defensive skills, and iconic 56-game hitting streak in 1941. DiMaggio won three MVP awards and helped the Yankees secure nine World Series titles. Beyond baseball, he became a cultural icon, notably through his marriage to actress Marilyn Monroe. He was inducted into the Baseball Hall of Fame in 1955.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Who was Joe DiMaggio? Respond in less than 100 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "765a269b-97b2-492b-940e-ac7d2c79e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'What country won the last soccer world cup?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As of my last knowledge update in October 2023, Argentina won the most recent FIFA World Cup, which took place in Qatar in 2022. They defeated France in the final. If you're looking for the most current information, please verify with the latest sources.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What country won the last soccer world cup?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76cb81-133f-449f-a626-a81c74bb0192",
   "metadata": {},
   "source": [
    "## Router Chain with LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e29463b-e3c8-4337-a830-8f668cd2b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rock_template = \"\"\"You are a very smart rock and roll professor. \\\n",
    "You are great at answering questions about rock and roll in a concise\\\n",
    "and easy to understand manner.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "rock_prompt = PromptTemplate.from_template(rock_template)\n",
    "\n",
    "politics_template = \"\"\"You are a very good politics professor. \\\n",
    "You are great at answering politics questions..\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "politics_prompt = PromptTemplate.from_template(politics_template)\n",
    "\n",
    "history_template = \"\"\"You are a very good history teacher. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_prompt = PromptTemplate.from_template(history_template)\n",
    "\n",
    "sports_template = \"\"\" You are a sports teacher.\\\n",
    "You are great at answering sports questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "sports_prompt = PromptTemplate.from_template(sports_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97c0e4ef-752e-4a93-a14c-2294ef53baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d83e739-6562-4060-a1bf-eedeabbcc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompt = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Answer the question as accurately as you can.\\n\\n{input}\"\n",
    ")\n",
    "prompt_branch = RunnableBranch(\n",
    "  (lambda x: x[\"topic\"] == \"rock\", rock_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"politics\", politics_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"history\", history_prompt),\n",
    "  (lambda x: x[\"topic\"] == \"sports\", sports_prompt),\n",
    "  general_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afa7b985-05b6-4285-970f-30c100ed6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# from langchain.pydantic_v1 import BaseModel\n",
    "from pydantic import BaseModel\n",
    "from langchain.output_parsers.openai_functions import PydanticAttrOutputFunctionsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "\n",
    "class TopicClassifier(BaseModel):\n",
    "    \"Classify the topic of the user question\"\n",
    "    \n",
    "    topic: Literal[\"rock\", \"politics\", \"history\", \"sports\"]\n",
    "    \"The topic of the user question. One of 'rock', 'politics', 'history', 'sports' or 'general'.\"\n",
    "\n",
    "\n",
    "classifier_function = convert_pydantic_to_openai_function(TopicClassifier)\n",
    "# llm = ChatOpenAI().bind(functions=[classifier_function], function_call={\"name\": \"TopicClassifier\"})\n",
    "llm = ChatOpenAI(model=MODEL_GPT).bind(functions=[classifier_function], function_call={\"name\": \"TopicClassifier\"})\n",
    "parser = PydanticAttrOutputFunctionsParser(pydantic_schema=TopicClassifier, attr_name=\"topic\")\n",
    "classifier_chain = llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "873263ad-0e81-4b8b-9a46-dd8f4615b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "# final_chain = (\n",
    "#     RunnablePassthrough.assign(topic=itemgetter(\"input\") | classifier_chain) \n",
    "#     | prompt_branch \n",
    "#     | ChatOpenAI()\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(topic=itemgetter(\"input\") | classifier_chain) \n",
    "    | prompt_branch \n",
    "    | ChatOpenAI(model=MODEL_GPT)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3fe884d-5713-412c-85a5-0d61ca21384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Napoleon Bonaparte was a French military leader and emperor who rose to prominence during the latter stages of the French Revolution and its associated wars. He was born on August 15, 1769, on the island of Corsica, which had just come under French control. He became one of the most influential figures in European history, known for his military genius, political reforms, and the establishment of a legal code that still bears his name.\\n\\nNapoleon's rise to power began with his military career, where he gained recognition for his leadership and strategic skills during campaigns in Italy and Egypt. In 1799, he staged a coup d'état, overthrowing the French Directory and establishing himself as First Consul. In 1804, he declared himself Emperor of the French, solidifying his control over the country.\\n\\nHis reign saw significant reforms, including the Napoleonic Code, which restructured French law and influenced legal systems in various countries worldwide. He also centralized administration, improved education, and promoted meritocracy in government and the military.\\n\\nNapoleon is best known for his military campaigns across Europe, collectively known as the Napoleonic Wars (1803-1815). He sought to expand French territory and influence, leading to a series of conflicts with various coalitions of European powers, including Britain, Austria, Prussia, and Russia.\\n\\nHowever, his ambition ultimately led to his downfall. The disastrous invasion of Russia in 1812 significantly weakened his army, and he faced a coalition of enemies that defeated him in 1814. He was exiled to the island of Elba but escaped in 1815, returning to power for a brief period known as the Hundred Days. His final defeat came at the Battle of Waterloo, after which he was exiled to the remote island of Saint Helena in the South Atlantic, where he died on May 5, 1821.\\n\\nNapoleon's legacy is complex; he is often celebrated for his contributions to modern governance and law, while also criticized for his authoritarian rule and the wars that caused widespread suffering across Europe. His impact on the course of European history is profound, shaping the political landscape for generations to come.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\"input\": \"Who was Napoleon Bonaparte?\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
