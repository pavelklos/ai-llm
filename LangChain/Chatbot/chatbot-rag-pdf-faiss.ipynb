{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff0c4a0-a548-46e1-bd28-b72d3395165c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RAG application with PDF, using FAISS as vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99954cfb-2c0c-4087-94c8-58ea68d8bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [REQUEST]\n",
    "#   Create basic RAG App with PDF locally and FAISS vector store, save and load vector store?\n",
    "# [RESPONSE]\n",
    "#   I'll provide a comprehensive example of creating a RAG application with a PDF,\n",
    "#   using FAISS as the vector store, and demonstrating how to save and load the vector store.\n",
    "#   Here's a step-by-step implementation:\n",
    "\n",
    "# [Install required packages]\n",
    "# pip install langchain-community langchain-openai faiss-cpu pypdf langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b3e746-5e52-4440-aa06-d56b7565f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799262da-ffe9-4e29-8d1a-943af8ffa940",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Set up OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ec5796-d5e7-4c77-9d70-2f7fa8ddde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API Key\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be69264-1000-42af-a9a1-8cab902a782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# load_dotenv(override = True)\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "MODEL_GPT=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb72f4d-17e4-403e-8c92-7c3e0a272cac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaee934-9352-4a13-9edb-9ca931a193f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the PDF\n",
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ecbc7d-1de9-4714-8519-3d1a93fc49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split the documents\n",
    "def split_documents(pages):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca103a5f-0273-4cd6-8342-66081a19f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Vector Store\n",
    "def create_vector_store(splits, embeddings):\n",
    "    vector_store = FAISS.from_documents(splits, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e84785-9d1c-409e-969a-53cb5b552ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save Vector Store\n",
    "def save_vector_store(vector_store, path):\n",
    "    vector_store.save_local(path)\n",
    "    print(f\"Vector store saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00eed84d-7a88-4408-8307-af8d324704b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load Vector Store\n",
    "def load_vector_store(path, embeddings):\n",
    "    loaded_store = FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)\n",
    "    return loaded_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1803455-2c37-495a-bcc6-932acaf5e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create RAG Chain\n",
    "def create_rag_chain(vector_store):\n",
    "    # Retriever\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "    # Prompt Template\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    # LLM\n",
    "    # llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    llm = ChatOpenAI(model=MODEL_GPT, temperature=0)\n",
    "    \n",
    "    # RAG Chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf0399-3b65-49a8-8bbd-68b6fac75d15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Path to your PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cc2ccf-056d-48cf-b4bc-871073283efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../../data/Be_Good.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7426a-c8ba-4d45-be53-56fbfbb819a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098315d4-9d71-4de3-8555-fe655abed394",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a22f1f-332a-4ca6-98b3-746458d9ec06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load and split PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0683bb-419a-4561-b144-f6f954a2ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = load_pdf(pdf_path)\n",
    "splits = split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd3ed0a-19cf-4aed-9c97-f65308de4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages))\n",
    "print(type(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997be36-62fa-41ac-b626-bfda8a2d5227",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e470cb0-139f-4c3f-bf43-b55ec4490109",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = create_vector_store(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61010c1-7c16-4510-ac59-43799b28f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vector_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d00e8-9525-454d-9652-b5534b4d3143",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Save Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72bfbd7-b8ad-49dd-b3bc-93529cbec15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved to faiss_index\n"
     ]
    }
   ],
   "source": [
    "save_vector_store(vector_store, \"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168334aa-f3bb-413e-a8cd-218c643344aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Vector Store (simulating a new session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4afa6485-220d-405a-9323-2967226d221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vector_store = load_vector_store(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4d74cb-d49d-4922-a687-bccdf87a9c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
     ]
    }
   ],
   "source": [
    "print(type(loaded_vector_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b2162-4b31-4b59-af78-0e43776b9955",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6adbb54a-f71b-43cc-bfb1-407ddd5f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_rag_chain(loaded_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f7f961-fd7a-4aa1-b3e3-faa0f99d8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(rag_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f6c51-1735-4de6-8190-05801ba18688",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e09bc53-0cd5-4d53-af63-40a79c06d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the main topic of this document?\"\n",
    "response = rag_chain.invoke(query)\n",
    "print(type(query))\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f832eff9-576e-4f12-af9d-d74599e97075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is the main topic of this document?\n",
      "\n",
      "Response: The main topic of the document is about the principles of creating successful startups, emphasizing the importance of making something that people want and prioritizing user satisfaction over immediate business models or profits. It discusses the idea that focusing on users can guide decision-making and lead to success.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuery:\", query)\n",
    "print(\"\\nResponse:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc997c-40da-4f3e-9c8b-c903a7f26798",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [chatbot-rag-pdf-faiss.py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661e1df-02d3-4820-b9d1-d075cbda4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import getpass\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# # Set up OpenAI API Key\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "# # 1. Load the PDF\n",
    "# def load_pdf(file_path):\n",
    "#     loader = PyPDFLoader(file_path)\n",
    "#     pages = loader.load()\n",
    "#     return pages\n",
    "\n",
    "# # 2. Split the documents\n",
    "# def split_documents(pages):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=1000, \n",
    "#         chunk_overlap=200\n",
    "#     )\n",
    "#     splits = text_splitter.split_documents(pages)\n",
    "#     return splits\n",
    "\n",
    "# # 3. Create Vector Store\n",
    "# def create_vector_store(splits, embeddings):\n",
    "#     vector_store = FAISS.from_documents(splits, embeddings)\n",
    "#     return vector_store\n",
    "\n",
    "# # 4. Save Vector Store\n",
    "# def save_vector_store(vector_store, path):\n",
    "#     vector_store.save_local(path)\n",
    "#     print(f\"Vector store saved to {path}\")\n",
    "\n",
    "# # 5. Load Vector Store\n",
    "# def load_vector_store(path, embeddings):\n",
    "#     loaded_store = FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)\n",
    "#     return loaded_store\n",
    "\n",
    "# # 6. Create RAG Chain\n",
    "# def create_rag_chain(vector_store):\n",
    "#     # Retriever\n",
    "#     retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "#     # Prompt Template\n",
    "#     template = \"\"\"Answer the question based only on the following context:\n",
    "#     {context}\n",
    "    \n",
    "#     Question: {question}\n",
    "#     \"\"\"\n",
    "#     prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "#     # LLM\n",
    "#     llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    \n",
    "#     # RAG Chain\n",
    "#     rag_chain = (\n",
    "#         {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#         | prompt\n",
    "#         | llm\n",
    "#         | StrOutputParser()\n",
    "#     )\n",
    "    \n",
    "#     return rag_chain\n",
    "\n",
    "# # Main Execution\n",
    "# def main():\n",
    "#     # Path to your PDF\n",
    "#     pdf_path = \"path/to/your/document.pdf\"\n",
    "    \n",
    "#     # Embeddings\n",
    "#     embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "#     # Load and split PDF\n",
    "#     pages = load_pdf(pdf_path)\n",
    "#     splits = split_documents(pages)\n",
    "    \n",
    "#     # Create Vector Store\n",
    "#     vector_store = create_vector_store(splits, embeddings)\n",
    "    \n",
    "#     # Save Vector Store\n",
    "#     save_vector_store(vector_store, \"faiss_index\")\n",
    "    \n",
    "#     # Load Vector Store (simulating a new session)\n",
    "#     loaded_vector_store = load_vector_store(\"faiss_index\", embeddings)\n",
    "    \n",
    "#     # Create RAG Chain\n",
    "#     rag_chain = create_rag_chain(loaded_vector_store)\n",
    "    \n",
    "#     # Example Query\n",
    "#     query = \"What is the main topic of this document?\"\n",
    "#     response = rag_chain.invoke(query)\n",
    "#     print(\"\\nQuery:\", query)\n",
    "#     print(\"\\nResponse:\", response)\n",
    "\n",
    "# # Run the main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
