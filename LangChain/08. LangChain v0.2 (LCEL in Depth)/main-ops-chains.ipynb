{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# Main Operations with LCEL Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc3c9c-e443-4a53-a3d6-98d8d23f76f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Contents\n",
    "* Chaining runnables, coercion\n",
    "* Multiple chains\n",
    "* Nested chains\n",
    "* Fallback for chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b4c9fa-4b29-45a5-8359-375af8073785",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03febb1-c3de-485a-ae2d-b68066790912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                                0.3.13\n",
      "langchain-chroma                         0.1.4\n",
      "langchain-community                      0.3.13\n",
      "langchain-core                           0.3.43\n",
      "langchain-experimental                   0.3.4\n",
      "langchain-google-community               2.0.7\n",
      "langchain-groq                           0.2.5\n",
      "langchain-openai                         0.2.14\n",
      "langchain-text-splitters                 0.3.4\n"
     ]
    }
   ],
   "source": [
    "# !pip list | grep langchain\n",
    "!pip list | findstr langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Connect with LLM and start conversation with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b84fd-b4c6-442f-bade-e801e6c7ad81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic chain: LLM model + prompt + output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa73509-0251-4951-9f9b-54ac1bcd73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write one brief sentence about {politician}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f3c0a8-bc37-45da-bd60-871f6d60c7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John F. Kennedy was the 35th President of the United States, serving from 1961 until his assassination in 1963.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"politician\": \"JFK\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f35c4-015d-4a0a-8d55-ad70046c9f40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mid-level chain: Retriever App Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aadaa7e-42e3-45c7-bacf-c3047a1fefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install docarray tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bdb403a-7cc7-4876-aa2b-07356bba0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken                                 0.8.0\n"
     ]
    }
   ],
   "source": [
    "# !pip list | grep tiktoken\n",
    "!pip list | findstr tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a3e0d5-a939-4339-a5dd-3a050087859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\miniconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"AI Accelera has provided Generative AI Training and Consulting Services in more than 100 countries\", \"Aceleradora AI is the branch of AI Accelera for the Spanish-Speaking market\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739774c6-5ec1-4f07-96a1-ec478d99ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "get_question_and_retrieve_relevant_docs = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec29ebf1-9b4b-471e-b004-41ecfa0f4d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Accelera has provided services in more than 100 countries.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = get_question_and_retrieve_relevant_docs | prompt | model | output_parser\n",
    "\n",
    "chain.invoke(\"In how many countries has AI Accelera provided services?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43fc04-90ca-4dcf-9aaf-3e1856b94f2c",
   "metadata": {},
   "source": [
    "* Graphic representation of what this chain does:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c07e27-69e8-4e02-ad9f-9d3b738c1693",
   "metadata": {},
   "source": [
    "![alt text](LCEL-chain-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830adc08-3c75-4e46-9754-355e15ea2fdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbe5383-9ac3-4c3c-b722-7a536cf2425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199d6899-a0bb-4a8f-b58d-a86eba2e3455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Alumni of AI Accelera are individuals who have been trained by the organization, totaling more than 7,000 from all continents and top companies.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"AI Accelera has trained more than 7.000 Alumni from all continents and top companies\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"who are the Alumni of AI Accelera?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675d1d4-5d30-45a0-8a2a-7e163627109b",
   "metadata": {},
   "source": [
    "### Rememeber: Syntax of RunnableParallel can have several variations\n",
    "* When composing RunnableParallel with another Runnable we do not need to wrap it up in RunnableParallel class. Inside chain, next three syntaxs are equivalent:\n",
    "    * `RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})`\n",
    "    * `RunnableParallel(context=retriever, question=RunnablePassthrough())`\n",
    "    * `{\"context\": retriever, \"question\": RunnablePassthrough()}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcf618-a9bc-40ce-b3ab-f970ee1bbadc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using itemgetter with RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16e9cca-a8a3-4f37-bd2e-fc8a9c0c1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AI Accelera be havin' trained more than 3,000 Enterprise Alumni, matey! Arrr!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"AI Accelera has trained more than 3,000 Enterprise Alumni.\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many Enterprise Alumni has trained AI Accelera?\", \"language\": \"Pirate English\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c333cb-4d5e-41b3-b007-8c4b1d175a93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13d185f-e00d-4842-9c99-87f3d4da7a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': {'num': 1}, 'transformed_output': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    user_input = RunnablePassthrough(),\n",
    "    transformed_output = lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f207a-fdb9-46cf-b1c0-06fbcf9b5e99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Chaining Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ba28a5-a605-482a-b3df-43a70e4dc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a sentence about {politician}\")\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d91592b-027a-4ea4-a764-94bf27b8610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neville Chamberlain, the British Prime Minister from 1937 to 1940, is best known for his policy of appeasement towards Adolf Hitler, particularly exemplified by the Munich Agreement of 1938.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Chamberlain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82645057-4570-4dd9-ad3b-58f0365bb4eb",
   "metadata": {},
   "source": [
    "### Coercion: Combine chain (which is Runnable) with other Runnables to create new chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8f1937-227a-4d4f-9e62-2b6792f00541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "historian_prompt = ChatPromptTemplate.from_template(\"Was {politician} positive for Humanity?\")\n",
    "\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98a3705-a6b0-473f-b4b8-7edd2dff9831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abraham Lincoln is widely regarded as a pivotal figure in American history, particularly for his leadership during the Civil War and his efforts to abolish slavery. Many historians and scholars argue that his actions had a profoundly positive impact on humanity for several reasons:\\n\\n1. **Abolition of Slavery**: Lincoln\\'s issuance of the Emancipation Proclamation in 1863 marked a significant step toward the abolition of slavery in the United States. While it did not immediately free all enslaved people, it paved the way for the eventual passage of the 13th Amendment, which formally abolished slavery.\\n\\n2. **Preservation of the Union**: Lincoln\\'s determination to preserve the Union during the Civil War is seen as crucial for maintaining the integrity of the United States. His leadership helped to prevent the fragmentation of the nation and set the stage for the country\\'s future development.\\n\\n3. **Promotion of Equality**: Lincoln\\'s rhetoric and policies increasingly emphasized the principles of equality and human rights. His famous Gettysburg Address articulated the idea of a government \"of the people, by the people, for the people,\" which resonates with democratic ideals and the importance of civil rights.\\n\\n4. **Legacy of Civil Rights**: Lincoln\\'s legacy has had a lasting influence on the civil rights movement and the ongoing struggle for equality in the United States. His actions set a precedent for future generations advocating for social justice and human rights.\\n\\nWhile Lincoln\\'s presidency was not without controversy and criticism—such as his views on race and the limitations of the Emancipation Proclamation—many believe that his overall contributions to the abolition of slavery and the preservation of the Union were fundamentally positive for humanity, fostering the ideals of freedom and equality.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Lincoln\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b650952f-a0b1-404e-ac63-1a11ed4f347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attila the Hun is a complex historical figure whose legacy is often viewed through various lenses. On one hand, he was indeed a formidable leader known for his military prowess and ability to unite various tribes under his banner, which allowed him to pose a significant threat to the Roman Empire during the 5th century. His campaigns led to widespread destruction and suffering, causing fear and instability across large parts of Europe.\\n\\nFrom a historical perspective, some might argue that his leadership led to the eventual transformation of Europe, as the movements of the Huns and the subsequent invasions contributed to the decline of the Western Roman Empire and the rise of new powers and cultures in Europe. This period of upheaval eventually led to the formation of medieval Europe.\\n\\nHowever, from a humanitarian standpoint, Attila\\'s conquests resulted in significant loss of life, displacement, and suffering for many people. His reputation as the \"Scourge of God\" reflects the devastation he brought to the regions he invaded. \\n\\nIn summary, while Attila the Hun\\'s actions contributed to significant historical changes, they were accompanied by considerable violence and suffering, making it difficult to label his impact on humanity as wholly positive. The assessment of his legacy often depends on the perspective one takes—whether one emphasizes the historical consequences of his actions or the humanitarian impact of his campaigns.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Attila\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7f6e6-7a4c-481b-b71a-445a291029ea",
   "metadata": {},
   "source": [
    "### Functions can also be included in Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7516f36d-d166-4534-a487-a103dbd1edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_chain_with_lambda = (\n",
    "    chain\n",
    "    | (lambda input: {\"politician\": input})\n",
    "    | historian_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7431d79-fa8f-4587-9c78-aae02acc0907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Maximilien Robespierre is a complex figure in the context of the French Revolution, and opinions about his legacy vary widely. On one hand, he is often seen as a champion of revolutionary ideals such as equality, social justice, and the rights of the common people. His advocacy for the abolition of slavery in the French colonies and his efforts to promote the welfare of the lower classes are viewed by some as progressive and positive contributions to humanity.\\n\\nOn the other hand, Robespierre is equally known for his role in the Reign of Terror, during which thousands were executed, including many who were deemed enemies of the revolution. This period is characterized by extreme political repression and violence, raising significant moral questions about the methods he employed in the name of revolutionary ideals. Critics argue that his extreme measures undermined the very principles of liberty and justice that the revolution sought to establish.\\n\\nIn summary, whether Robespierre's actions were ultimately positive for humanity depends on one's perspective. His commitment to revolutionary principles can be seen as a force for good, while his methods and the resultant violence have led many to view him as a negative figure in history. The legacy of Robespierre remains a subject of significant debate among historians and scholars.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain_with_lambda.invoke({\"politician\": \"Robespierre\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cebf2-c24f-4bb5-bb8f-bcd2daf72f82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Multiple chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172fd045-567e-40bc-8e42-e8f3923ca1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'François Mitterrand vient de France, qui est située en Europe.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the country {politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what continent is the country {country} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "# model = ChatOpenAI()\n",
    "model = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Miterrand\", \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47ead9-7fb7-4fa2-951e-50026e04b43c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nested chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b788e91c-3afe-461c-9080-086c37f26a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\"\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"soccer_player\": RunnablePassthrough() \n",
    "        | RunnableLambda(russian_lastname_from_dictionary), \n",
    "        \"operation_c\": RunnablePassthrough()\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc6d31c5-be72-4c95-80ab-944843450e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Roman Abramovich, the Russian businessman and former owner of Chelsea Football Club, is that he has a background in oil and gas. Before making his fortune in the oil industry, Abramovich was an entrepreneur in various businesses, including selling rubber ducks and other toys. His rise to prominence in the oil sector, particularly through his ownership of Sibneft, was a key factor in his wealth accumulation, helping him later to acquire Chelsea in 2003. His diverse early ventures highlight a remarkable transition from small-scale entrepreneurship to becoming one of the most well-known figures in international sports and business.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e51df-c2fc-47d5-85d4-c4717bf32603",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fallback for chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "509b9f90-648c-48da-acbf-206519e74966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a chain with a ChatModel\n",
    "# We add in a string output parser here so the outputs between the two are the same type\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a funny assistant who always includes a joke in your response\",\n",
    "        ),\n",
    "        (\"human\", \"Who is the best {sport} player worldwide?\"),\n",
    "    ]\n",
    ")\n",
    "# Here we're going to use a bad model name to easily create a chain that will error\n",
    "chat_model = ChatOpenAI(model=\"gpt-fake\")\n",
    "\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d75321e-ec9c-41a3-9377-1b26d7ced7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a chain with the normal OpenAI model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt_template = \"\"\"Instructions: You're a funny assistant who always includes a joke in your response.\n",
    "\n",
    "Question: Who is the best {sport} player worldwide?\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = OpenAI()\n",
    "llm = ChatOpenAI(model=MODEL_GPT)\n",
    "\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b6231c-ef6e-4d18-ba22-b92888e515cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, the age-old debate! Some say Lionel Messi, others swear by Cristiano Ronaldo. It’s like trying to decide if pizza or tacos are the best food—both are delicious, but it really depends on your mood! Speaking of soccer, why did the soccer player bring string to the game? Because he wanted to tie the score! 😄', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 32, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-1dedf5ae-53c2-4d62-a000-d3a780564300-0', usage_metadata={'input_tokens': 32, 'output_tokens': 71, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now create a final chain which combines the two\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "\n",
    "chain.invoke({\"sport\": \"soccer\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
