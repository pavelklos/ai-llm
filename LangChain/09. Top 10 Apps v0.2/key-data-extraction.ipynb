{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Key Data Extraction App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* We will create app to **extract structured information from unstructured text**. Imagine, for example, that you want to extract name, lastname and country of users that submit comments in website of your company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1469bf6c-05e6-4966-8a9a-f20c8d1eb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba89426-c952-43a3-aa6c-a7430d7aa8c1",
   "metadata": {},
   "source": [
    "## Define what information we want to extract\n",
    "* **We'll use Pydantic to define schema to extract personal information**.\n",
    "* **Document attributes and schema itself**: This information is sent to LLM and is used to improve quality of information extraction.\n",
    "* Do not force LLM to make up information! **We import Optional for attributes allowing LLM to output None if it doesn't know answer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b3d81a-e4d3-4956-807b-1ab147146390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"The lastname of the person if known\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"The country of the person if known\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219dde9c-3139-442c-a3be-1b9185f7a644",
   "metadata": {},
   "source": [
    "## Define Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab077d5b-d86c-4d0e-baac-b19cbe6ace83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c14b0-976b-4340-bcb3-46109584d987",
   "metadata": {},
   "source": [
    "* We need to use model that supports function/tool calling.\n",
    "* Please review [documentation](https://python.langchain.com/v0.2/docs/concepts/#function-tool-calling) for list of some models that can be used with this API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb3cd0d-fc9a-4223-a1ef-5857dc0e4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05698c54-da74-4ff5-b7ff-d9bb22d6f726",
   "metadata": {},
   "source": [
    "## Try app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082c7c53-0a94-4a59-b5a7-d3a186402467",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I absolutely love this product! It's been a game-changer for my daily routine. The quality is top-notch and the customer service is outstanding. I've recommended it to all my friends and family. - Sarah Johnson, USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39cb512c-5b2e-4aeb-9821-6395809a8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Sarah', lastname='Johnson', country='USA')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05023e96-9c9b-4102-b902-7e244b78ee6f",
   "metadata": {},
   "source": [
    "* **Note that this extraction capability is generative**, which means that our model can perform variety of tasks beyond expected. For instance, model could infer gender of user from their name, even when this information is not explicitly provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14033470-3abb-4cc5-ad4c-da9370e0a6d6",
   "metadata": {},
   "source": [
    "## Extraction of list of entities rather than single entity\n",
    "* In real projects you will be extracting list of entities rather than single entity. **This can be easily achieved using pydantic by nesting models inside one another**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40267cdd-9e8c-4ca8-b90f-4197b99f3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"The lastname of the person if known\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"The country of the person if known\"\n",
    "    )\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4572231-c88c-474f-8421-788ed4f1115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39646a67-a02c-4e80-a2ad-3ea2cf6b8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I'm so impressed with this product! It has truly transformed how I approach my daily tasks. The quality exceeds my expectations, and the customer support is truly exceptional. I've already suggested it to all my colleagues and relatives. - Emily Clarke, Canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ffbad47-807a-4607-b4e1-e6b472b2c9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Emily', lastname='Clarke', country='Canada')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
