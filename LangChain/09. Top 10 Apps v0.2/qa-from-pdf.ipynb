{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# QA over PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* We will create Q&A app that can answer questions about PDF files.\n",
    "* We will use Document Loader to load text in format usable by LLM, then build retrieval-augmented generation (RAG) pipeline to answer questions, including citations from source material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea036db-aa90-4196-b9d4-0981fd40e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99edb898-4503-429d-ad7d-fad4fc74300f",
   "metadata": {},
   "source": [
    "## Load PDF file\n",
    "* Loader reads PDF at the specified path into memory.\n",
    "* It then extracts text data using pypdf package.\n",
    "* Finally, it creates LangChain Document for each page of PDF with the page's content and some metadata about where in document the text came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6903027c-722c-4b9f-8717-b3affb844227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a191a2-133a-4bae-be2c-0b9f226c0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764957d8-b4b3-4555-affc-187203e85293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# file_path = \"./data/Be_Good.pdf\"\n",
    "file_path = \"../../data/Be_Good.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb64f5c-d5da-4c60-9418-a9d5407faa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be Good - Essay by Paul Graham\n",
      "Be Good\n",
      "Be good\n",
      "April 2008(This essay is derived from a talk at the 2\n",
      "{'source': '../../data/Be_Good.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1148577-8c06-47fb-9d48-fa9ce7f14e30",
   "metadata": {},
   "source": [
    "## RAG\n",
    "* We will use vector database (vector store) Chroma DB.\n",
    "* Using text splitter, we will split loaded PDF into smaller documents that can more easily fit into LLM's context window, then load them into vector store.\n",
    "* We can then create retriever from vector store for use in our RAG chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21711cdc-510e-4738-b8ba-28135b4b7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ae6680-d314-435f-9213-ffb66bac7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f674aa-167a-46f1-8e5c-c7f62d237092",
   "metadata": {},
   "source": [
    "* We will then use some built-in helpers to construct final rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac58036b-b6bc-44d6-8d76-b6141d8a9da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article \"Be Good\" by Paul Graham discusses the importance of creating products that people want and not overly focusing on business models in the early stages of startups. It emphasizes the value of user feedback and the \"tamagotchi effect,\" where having users to care for can drive a startup\\'s development and success. Additionally, it draws parallels between startups and charitable endeavors, highlighting the significance of good intentions and accountability.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"What is this article about?\"})\n",
    "\n",
    "results[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89746b08-1ae3-4f9b-971d-449a32d9c7e7",
   "metadata": {},
   "source": [
    "* If you print whole `results` you will see that you get both the final answer in answer key of results dict, and the context the LLM used to generate answer. See it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e341ec-36f7-4703-97d5-ce71cd2ecac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this article about?',\n",
       " 'context': [Document(metadata={'page': 0, 'source': '../../data/Be_Good.pdf'}, page_content=\"Be Good - Essay by Paul Graham\\nBe Good\\nBe good\\nApril 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we\\nstarted Y Combinator we came up with the\\nphrase that became our motto: Make something people want.  We've\\nlearned a lot since then, but if I were choosing now that's still\\nthe one I'd pick.Another thing we tell founders is not to worry too much about the\\nbusiness model, at least at first.  Not because making money is\\nunimportant, but because it's so much easier than building something\\ngreat.A couple weeks ago I realized that if you put those two ideas\\ntogether, you get something surprising.  Make something people want.\\nDon't worry too much about making money.  What you've got is a\\ndescription of a charity.When you get an unexpected result like this, it could either be a\\nbug or a new discovery.  Either businesses aren't supposed to be\\nlike charities, and we've proven by reductio ad absurdum that one\"),\n",
       "  Document(metadata={'page': 10, 'source': '../../data/Be_Good.pdf'}, page_content=\"Be Good - Essay by Paul Graham\\nGoogle does.Most explicitly benevolent projects don't hold themselves sufficiently\\naccountable.  They act as if having good intentions were enough to\\nguarantee good effects.[3] Users dislike their\\nnew operating system so much that they're starting petitions to\\nsave the old one.  And the old one was nothing special.  The hackers\\nwithin Microsoft must know in their hearts that if the company\\nreally cared about users they'd just advise them to switch to OSX.Thanks to Trevor Blackwell, Paul\\nBuchheit, Jessica Livingston,\\nand Robert Morris for reading drafts of this.\\nPage 11\"),\n",
       "  Document(metadata={'page': 1, 'source': '../../data/Be_Good.pdf'}, page_content=\"Be Good - Essay by Paul Graham\\ncaptains always try to get upwind\\nof their opponents.  If you're upwind, you decide when and if to\\nengage the other ship.  Craigslist is effectively upwind of enormous\\nrevenues.  They'd face some challenges if they wanted to make more,\\nbut not the sort you face when you're tacking upwind, trying to\\nforce a crappy product on ambivalent users by spending ten times\\nas much on sales as on development.  [1]I'm not saying startups should aim to end up like\\nCraigslist.\\nThey're a product of unusual circumstances.  But they're a good\\nmodel for the early phases.Google looked a lot like a charity in the beginning. They didn't\\nhave ads for over a year.  At year 1, Google was indistinguishable\\nfrom a nonprofit.  If a nonprofit or government organization had\\nstarted a project to index the web, Google at year 1 is the limit\\nof what they'd have produced.Back when I was working on spam filters I thought it would be a\"),\n",
       "  Document(metadata={'page': 5, 'source': '../../data/Be_Good.pdf'}, page_content=\"Be Good - Essay by Paul Graham\\nyou've basically built yourself a giant tamagotchi.  You've made\\nsomething you need to take care of.Blogger is a famous example of a startup that went through\\nreally\\nlow lows and survived.  At one point they ran out of money and\\neveryone left. Evan Williams came in to work the next day, and there\\nwas no one but him.  What kept him going?  Partly that users needed\\nhim.  He was hosting thousands of people's blogs. He couldn't just\\nlet the site die.There are many advantages of launching quickly, but the most important\\nmay be that once you have users, the tamagotchi effect kicks in.\\nOnce you have users to take care of, you're forced to figure out\\nwhat will make them happy, and that's actually very valuable\\ninformation.The added confidence that comes from trying to help people can\\nalso help you with investors. One of the founders of \\nChatterous told \\nme recently that he and his cofounder had decided that this service\")],\n",
       " 'answer': 'The article \"Be Good\" by Paul Graham discusses the importance of creating products that people want and not overly focusing on business models in the early stages of startups. It emphasizes the value of user feedback and the \"tamagotchi effect,\" where having users to care for can drive a startup\\'s development and success. Additionally, it draws parallels between startups and charitable endeavors, highlighting the significance of good intentions and accountability.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2153a091-c9cb-489e-b505-c9691b4cc774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': '../../data/Be_Good.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(results[\"context\"][0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
