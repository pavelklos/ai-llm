{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Conversational RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* In many Q&A applications we want to allow user to have back-and-forth conversation, meaning that application needs some sort of \"memory\" of past questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9fdf08-2b7c-4afc-934b-ce41090b7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(model=MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc942a2e-b9d3-4f5f-a612-f212cacc8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community langchainhub langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f596c-4904-49b2-ad65-7c10988d5bf5",
   "metadata": {},
   "source": [
    "## Basic RAG without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f29f71-3210-47b4-91d2-82ae30d11c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# loader = TextLoader(\"./data/be-good.txt\")\n",
    "loader = TextLoader(\"../../data/be-good.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97dff6a-e703-4ed9-9701-3e08cbaabb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7772399b-c563-4a46-9051-2c66344c632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rag_chain.invoke({\"input\": \"What is this article about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b471ef7-7723-4b24-9769-27381ada7dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article discusses the principles of creating successful startups, emphasizing the importance of making something people want while not overly focusing on the business model initially. It suggests that a business can operate similarly to a charity, where good intentions and user satisfaction lead to success, using Craigslist as an example. The author reflects on the balance between benevolence and profitability in entrepreneurship.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cc6fb8-0778-4df4-880f-d4957ff90c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rag_chain.invoke({\"input\": \"What was my previous question about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6660b23a-4203-44c8-a516-84bf9b233f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ccd21-2c4c-4ebe-b27b-59daa0db8ba2",
   "metadata": {},
   "source": [
    "## Adding memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb66712-913d-4943-831b-ea80aeda1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b154434-7bdd-48e8-9438-5839c2a186d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a1e69d-105f-492c-9b2f-c956522ababd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your previous question was about the content and focus of the article, asking what it is about.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is this article about?\"\n",
    "\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_question = \"What was my previous question about?\"\n",
    "\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2173cc2c-859a-435f-92f8-071fd84e3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57be5f77-c58b-4910-86e5-76e3430634f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article discusses the principles of creating successful businesses, emphasizing the importance of making something people want and not overly focusing on immediate profitability. It critiques the notion that well-intentioned projects automatically yield positive outcomes, using examples like Craigslist to illustrate a model that operates successfully without traditional profit-driven motives. Overall, it suggests a potential new approach to business that aligns more closely with charitable principles.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is this article about?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"001\"}\n",
    "    },  # constructs a key \"001\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76537066-9b6a-49bf-bc23-665feacacd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your previous question was about the content or main theme of the article.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What was my previous question about?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"001\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d8d41e-a2f1-4cc2-8833-c41e60d62e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is this article about?\n",
      "\n",
      "AI: The article discusses the principles of creating successful businesses, emphasizing the importance of making something people want and not overly focusing on immediate profitability. It critiques the notion that well-intentioned projects automatically yield positive outcomes, using examples like Craigslist to illustrate a model that operates successfully without traditional profit-driven motives. Overall, it suggests a potential new approach to business that aligns more closely with charitable principles.\n",
      "\n",
      "User: What was my previous question about?\n",
      "\n",
      "AI: Your previous question was about the content or main theme of the article.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in store[\"001\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
